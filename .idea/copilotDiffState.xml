<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/Jenkinsfile">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Jenkinsfile" />
              <option name="originalContent" value="// filepath: /home/mamadbah/Java/mr-jenk/Jenkinsfile.optimized&#10;pipeline {&#10;    agent any&#10;&#10;    // NOTE: Tous les stages s'exécutent sur le même agent (Jenkins choisit un agent disponible)&#10;&#10;    options {&#10;        buildDiscarder(logRotator(numToKeepStr: '10'))&#10;        timeout(time: 60, unit: 'MINUTES')&#10;        timestamps()&#10;        disableConcurrentBuilds()&#10;    }&#10;&#10;    environment {&#10;        DOCKER_HUB_USER = 'mamadbah2'&#10;        IMAGE_VERSION = &quot;${env.BUILD_NUMBER}&quot;&#10;        GITHUB_TOKEN = credentials('GITHUB_TOKEN')&#10;&#10;        // Préfixe pour éviter les conflits entre projets&#10;        PROJECT_NAME = 'safe-zone'&#10;&#10;        // Media Service credentials&#10;        MONGODB_URI = credentials('MONGODB_URI_BOBO')&#10;        MONGODB_DATABASE = credentials('MONGODB_DATABASE')&#10;        SUPABASE_PROJECT_URL = credentials('SUPABASE_PROJECT_URL')&#10;        SUPABASE_API_KEY = credentials('SUPABASE_API_KEY')&#10;        SUPABASE_BUCKET_NAME = credentials('SUPABASE_BUCKET_NAME')&#10;&#10;        // Cache directories - améliore la performance&#10;        MAVEN_OPTS = '-Dmaven.repo.local=.m2/repository -Dmaven.artifact.threads=10'&#10;        NPM_CONFIG_CACHE = '.npm-cache'&#10;        DOCKER_BUILDKIT = '0'&#10;        COMPOSE_DOCKER_CLI_BUILD = '0'&#10;    }&#10;&#10;    stages {&#10;&#10;        stage('Clean Workspace') {&#10;            steps {&#10;                echo ' Nettoyage de l\'espace de travail...'&#10;                sh '''&#10;                    # Nettoyer seulement les conteneurs et images de l'ancien build&#10;                    docker-compose down -v --remove-orphans || true&#10;                    docker images | grep &quot;my_buy01_pipeline2&quot; | grep -v &quot;${IMAGE_VERSION}&quot; | awk '{print $3}' | xargs -r docker rmi -f || true&#10;                '''&#10;            }&#10;        }&#10;&#10;        stage('Build &amp; Unit Tests') {&#10;            parallel {&#10;                stage('Frontend') {&#10;                    steps {&#10;                        echo ' Tests Frontend Angular (Headless)...'&#10;                        dir('buy-01-frontend') {&#10;                            sh '''&#10;                                npm ci --cache ${NPM_CONFIG_CACHE}&#10;                                npm run test:headless&#10;                            '''&#10;                        }&#10;                    }&#10;                }&#10;&#10;                stage('Backend Services') {&#10;                    steps {&#10;                        echo ' Build et Tests des Services Backend...'&#10;                        script {&#10;                            def services = ['discovery-service', 'config-service', 'api-gateway', 'product-service', 'user-service', 'media-service']&#10;                            services.each { svc -&gt;&#10;                                echo &quot; Build et test de ${svc}...&quot;&#10;                                sh &quot;&quot;&quot;&#10;                                    mvn -f ${svc}/pom.xml clean verify \&#10;                                        --batch-mode \&#10;                                        -Dmaven.test.failure.ignore=false&#10;                                &quot;&quot;&quot;&#10;                            }&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;            post {&#10;                always {&#10;                    // Les rapports JUnit et les artefacts proviennent des agents; nous archiveons depuis le contrôleur&#10;                    // pour éviter les problèmes d'accès, on copie d'abord les artefacts si nécessaire.&#10;                    junit allowEmptyResults: true, testResults: '**/target/surefire-reports/*.xml'&#10;                    archiveArtifacts artifacts: '**/target/*.jar', allowEmptyArchive: true&#10;                }&#10;            }&#10;        }&#10;&#10;       // groovy&#10;       stage('Code Quality (Sonar + Gate)') {&#10;           steps {&#10;               echo ' Analyses Sonar en parallèle + attente des Quality Gates...'&#10;               script {&#10;                   def services = ['discovery-service','config-service','api-gateway','product-service','user-service','media-service']&#10;                   def parallelQuality = [:]&#10;&#10;                   services.each { svc -&gt;&#10;                       parallelQuality[svc] = {&#10;                           echo &quot; Sonar pour ${svc}...&quot;&#10;                           dir(svc) {&#10;                               // Move the Sonar wrapper and credentials inside each parallel branch&#10;                               withSonarQubeEnv('safe-zone-mr-jenk') {&#10;                                   withCredentials([string(credentialsId: 'SONAR_USER_TOKEN', variable: 'SONAR_USER_TOKEN')]) {&#10;                                       def jacocoOption = (svc in ['product-service','user-service','media-service']) ?&#10;                                           &quot;-Dsonar.coverage.jacoco.xmlReportPaths=target/site/jacoco/jacoco.xml&quot; : &quot;&quot;&#10;&#10;                                       sh &quot;&quot;&quot;&#10;                                           mvn sonar:sonar \&#10;                                               -Dsonar.projectKey=sonar-${svc.replace('-service','')} \&#10;                                               -Dsonar.host.url=$SONAR_HOST_URL \&#10;                                               -Dsonar.token=$SONAR_USER_TOKEN \&#10;                                               -Dsonar.java.binaries=target/classes \&#10;                                               ${jacocoOption}&#10;                                       &quot;&quot;&quot;&#10;                                   } // withCredentials&#10;                               } // withSonarQubeEnv&#10;&#10;                               // waitForQualityGate must run in the same workspace/context&#10;                               timeout(time: 10, unit: 'MINUTES') {&#10;                                   waitForQualityGate abortPipeline: true&#10;                               }&#10;                           } // dir&#10;                       }&#10;                   }&#10;&#10;                   parallel parallelQuality&#10;               }&#10;           }&#10;       }&#10;&#10;&#10;&#10;        stage('Build Docker Images') {&#10;            steps {&#10;                echo ' Construction des images Docker en parallèle...'&#10;                script {&#10;                    def services = ['eureka-server', 'config-service', 'api-gateway', 'product-service', 'user-service', 'media-service', 'frontend']&#10;                    def parallelBuilds = [:]&#10;&#10;                    services.each { service -&gt;&#10;                        parallelBuilds[service] = {&#10;                            def serviceDir = service == 'frontend' ? 'buy-01-frontend' : service.replace('eureka-server', 'discovery-service')&#10;                            echo &quot; Construction de ${service}...&quot;&#10;                            sh &quot;&quot;&quot;&#10;                                docker build -t my_buy01_pipeline2-${service}:latest \&#10;                                    --build-arg MAVEN_OPTS=&quot;-Dmaven.test.skip=true&quot; \&#10;                                    --cache-from ${DOCKER_HUB_USER}/${PROJECT_NAME}-${service}:latest \&#10;                                    -f ${serviceDir}/Dockerfile \&#10;                                    ${serviceDir}&#10;                            &quot;&quot;&quot;&#10;                        }&#10;                    }&#10;&#10;                    parallel parallelBuilds&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Integration Tests') {&#10;            steps {&#10;                echo ' Tests d\'intégration...'&#10;                script {&#10;                    timeout(time: 10, unit: 'MINUTES') {&#10;                        try {&#10;                            withEnv([&#10;                                &quot;IMAGE_VERSION=${env.BUILD_NUMBER}&quot;,&#10;                                &quot;PROJECT_NAME=${PROJECT_NAME}&quot;,&#10;                                &quot;GITHUB_TOKEN=${env.GITHUB_TOKEN}&quot;,&#10;                                &quot;SUPABASE_PROJECT_URL=${env.SUPABASE_PROJECT_URL}&quot;,&#10;                                &quot;SUPABASE_API_KEY=${env.SUPABASE_API_KEY}&quot;,&#10;                                &quot;SUPABASE_BUCKET_NAME=${env.SUPABASE_BUCKET_NAME}&quot;,&#10;                                &quot;MONGODB_URI=${env.MONGODB_URI}&quot;,&#10;                                &quot;MONGODB_DATABASE=${env.MONGODB_DATABASE}&quot;&#10;                            ]) {&#10;                                sh '''&#10;                                    docker-compose up -d&#10;&#10;                                    # Attendre que les services soient prêts avec health checks&#10;                                    echo &quot;⏳ Attente du démarrage des services...&quot;&#10;                                    for i in {1..40}; do&#10;                                        if docker-compose ps | grep -E &quot;(healthy|running)&quot; | wc -l | grep -q 7; then&#10;                                            echo &quot;✅ Tous les services sont démarrés&quot;&#10;                                            break&#10;                                        fi&#10;                                        echo &quot;Tentative $i/40...&quot;&#10;                                        sleep 5&#10;                                    done&#10;&#10;                                    # Vérifier que les services sont en bonne santé&#10;                                    docker-compose ps&#10;                                '''&#10;                            }&#10;                        } finally {&#10;                            sh 'docker-compose logs --tail=50'&#10;                            sh 'docker-compose down -v --remove-orphans'&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Push to Docker Hub') {&#10;            steps {&#10;                script {&#10;                    echo ' Push des images vers Docker Hub...'&#10;&#10;                    withCredentials([usernamePassword(&#10;                        credentialsId: 'dockerhub-credential',&#10;                        usernameVariable: 'DOCKER_USER',&#10;                        passwordVariable: 'DOCKER_PASS'&#10;                    )]) {&#10;                        sh 'echo $DOCKER_PASS | docker login -u $DOCKER_USER --password-stdin'&#10;                    }&#10;&#10;                    def services = ['frontend', 'product-service', 'user-service', 'media-service', 'api-gateway', 'config-service', 'eureka-server']&#10;                    def parallelPushes = [:]&#10;&#10;                    services.each { service -&gt;&#10;                        parallelPushes[service] = {&#10;                            def localImageName = &quot;my_buy01_pipeline2-${service}&quot;&#10;                            // Préfixer avec PROJECT_NAME pour éviter les conflits entre applications&#10;                            def taggedImageName = &quot;${DOCKER_HUB_USER}/${PROJECT_NAME}-${service}:${env.BUILD_NUMBER}&quot;&#10;                            def latestImageName = &quot;${DOCKER_HUB_USER}/${PROJECT_NAME}-${service}:latest&quot;&#10;&#10;                            echo &quot; Push de ${service}...&quot;&#10;                            sh &quot;&quot;&quot;&#10;                                docker tag ${localImageName}:latest ${taggedImageName}&#10;                                docker tag ${localImageName}:latest ${latestImageName}&#10;                                docker push ${taggedImageName}&#10;                                docker push ${latestImageName}&#10;                            &quot;&quot;&quot;&#10;                        }&#10;                    }&#10;&#10;                    parallel parallelPushes&#10;&#10;                    sh 'docker logout'&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Deploy Locally') {&#10;            steps {&#10;                script {&#10;                    echo &quot; Déploiement local, version ${env.BUILD_NUMBER}...&quot;&#10;&#10;                    timeout(time: 10, unit: 'MINUTES') {&#10;                        withEnv([&#10;                            &quot;IMAGE_VERSION=${env.BUILD_NUMBER}&quot;,&#10;                            &quot;PROJECT_NAME=${PROJECT_NAME}&quot;,&#10;                            &quot;GITHUB_TOKEN=${env.GITHUB_TOKEN}&quot;,&#10;                            &quot;SUPABASE_PROJECT_URL=${env.SUPABASE_PROJECT_URL}&quot;,&#10;                            &quot;SUPABASE_API_KEY=${env.SUPABASE_API_KEY}&quot;,&#10;                            &quot;SUPABASE_BUCKET_NAME=${env.SUPABASE_BUCKET_NAME}&quot;,&#10;                            &quot;MONGODB_URI=${env.MONGODB_URI}&quot;,&#10;                            &quot;MONGODB_DATABASE=${env.MONGODB_DATABASE}&quot;&#10;                        ]) {&#10;                            sh '''&#10;                                docker-compose -f docker-compose-deploy.yml down&#10;                                docker-compose -f docker-compose-deploy.yml pull&#10;                                docker-compose -f docker-compose-deploy.yml up -d&#10;&#10;                                # Vérifier l'état des conteneurs&#10;                                echo &quot;⏳ Attente du démarrage...&quot;&#10;                                for i in {1..20}; do&#10;                                    if docker-compose -f docker-compose-deploy.yml ps | grep -q &quot;Up&quot;; then&#10;                                        echo &quot;✅ Services démarrés&quot;&#10;                                        break&#10;                                    fi&#10;                                    echo &quot;Tentative $i/20...&quot;&#10;                                    sleep 3&#10;                                done&#10;                                docker-compose -f docker-compose-deploy.yml ps&#10;                            '''&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Health Check') {&#10;            steps {&#10;                script {&#10;                    echo ' Vérification de la santé des services...'&#10;                    timeout(time: 5, unit: 'MINUTES') {&#10;                        sh '''&#10;                            # Attendre que tous les services soient en bonne santé&#10;                            for i in {1..30}; do&#10;                                if docker-compose -f docker-compose-deploy.yml ps | grep -q &quot;unhealthy&quot;; then&#10;                                    echo &quot;⏳ Attente de la santé des services... ($i/30)&quot;&#10;                                    sleep 10&#10;                                else&#10;                                    echo &quot;✅ Tous les services sont en bonne santé&quot;&#10;                                    exit 0&#10;                                fi&#10;                            done&#10;&#10;                            echo &quot;❌ Timeout: certains services ne sont pas en bonne santé&quot;&#10;                            docker-compose -f docker-compose-deploy.yml ps&#10;                            exit 1&#10;                        '''&#10;                    }&#10;                }&#10;            }&#10;        }&#10;    }&#10;&#10;    post {&#10;        success {&#10;            script {&#10;                // s'assurer que les commandes Docker du post s'exécutent sur le noeud contrôleur&#10;                node {&#10;                    // Nettoyer les anciennes images&#10;                    sh '''&#10;                        docker images | grep &quot;${DOCKER_HUB_USER}&quot; | grep -v &quot;${IMAGE_VERSION}&quot; | grep -v &quot;latest&quot; | awk '{print $3}' | xargs -r docker rmi -f || true&#10;                    '''&#10;&#10;                    mail(&#10;                        to: 'bahmamadoubobosewa@gmail.com',&#10;                        subject: &quot;SUCCESS: Pipeline ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;,&#10;                        body: &quot;Le pipeline a réussi.\nJob: ${env.JOB_NAME}\nBuild: ${env.BUILD_NUMBER}\nVoir les détails: ${env.BUILD_URL}&quot;&#10;                    )&#10;                }&#10;            }&#10;        }&#10;&#10;        failure {&#10;            script {&#10;                echo &quot;⚠️ Pipeline échouée, rollback en cours...&quot;&#10;&#10;                def lastSuccessfulBuild = currentBuild.previousSuccessfulBuild&#10;&#10;                node {&#10;                    if (lastSuccessfulBuild &amp;&amp; lastSuccessfulBuild.number != env.BUILD_NUMBER) {&#10;                        echo &quot; Rollback vers la version ${lastSuccessfulBuild.number}...&quot;&#10;                        try {&#10;                            withEnv([&quot;IMAGE_VERSION=${lastSuccessfulBuild.number}&quot;]) {&#10;                                sh '''&#10;                                    docker-compose -f docker-compose-deploy.yml down&#10;                                    docker-compose -f docker-compose-deploy.yml pull&#10;                                    docker-compose -f docker-compose-deploy.yml up -d&#10;                                '''&#10;                            }&#10;                            echo &quot;✅ Rollback réussi vers la version ${lastSuccessfulBuild.number}&quot;&#10;                        } catch (Exception e) {&#10;                            echo &quot;❌ Échec du rollback: ${e.message}&quot;&#10;                        }&#10;                    } else {&#10;                        echo &quot;⚠️ Aucune version précédente disponible pour rollback.&quot;&#10;                    }&#10;&#10;                    mail(&#10;                        to: 'bahmamadoubosewa@gmail.com',&#10;                        subject: &quot;FAILURE: Pipeline ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;,&#10;                        body: &quot;Le pipeline a echoue.\nJob: ${env.JOB_NAME}\nBuild: ${env.BUILD_NUMBER}\nVoir les détails: ${env.BUILD_URL}&quot;&#10;                    )&#10;                }&#10;            }&#10;        }&#10;&#10;        always {&#10;            script {&#10;                node {&#10;                    echo ' Nettoyage final...'&#10;                    sh '''&#10;                        # Nettoyer les conteneurs arrêtés et les images dangereuses&#10;                        docker container prune -f || true&#10;                        docker image prune -f || true&#10;                    '''&#10;                }&#10;            }&#10;        }&#10;    }&#10;}&#10;" />
              <option name="updatedContent" value="// filepath: /home/mamadbah/Java/mr-jenk/Jenkinsfile.optimized&#10;pipeline {&#10;    agent any&#10;&#10;    // NOTE: Tous les stages s'exécutent sur le même agent (Jenkins choisit un agent disponible)&#10;&#10;    options {&#10;        buildDiscarder(logRotator(numToKeepStr: '10'))&#10;        timeout(time: 60, unit: 'MINUTES')&#10;        timestamps()&#10;        disableConcurrentBuilds()&#10;    }&#10;&#10;    environment {&#10;        DOCKER_HUB_USER = 'mamadbah2'&#10;        IMAGE_VERSION = &quot;${env.BUILD_NUMBER}&quot;&#10;        GITHUB_TOKEN = credentials('GITHUB_TOKEN')&#10;&#10;        // Préfixe pour éviter les conflits entre projets&#10;        PROJECT_NAME = 'safe-zone'&#10;&#10;        // Media Service credentials&#10;        MONGODB_URI = credentials('MONGODB_URI_BOBO')&#10;        MONGODB_DATABASE = credentials('MONGODB_DATABASE')&#10;        SUPABASE_PROJECT_URL = credentials('SUPABASE_PROJECT_URL')&#10;        SUPABASE_API_KEY = credentials('SUPABASE_API_KEY')&#10;        SUPABASE_BUCKET_NAME = credentials('SUPABASE_BUCKET_NAME')&#10;&#10;        // Cache directories - améliore la performance&#10;        MAVEN_OPTS = '-Dmaven.repo.local=.m2/repository -Dmaven.artifact.threads=10'&#10;        NPM_CONFIG_CACHE = '.npm-cache'&#10;        DOCKER_BUILDKIT = '0'&#10;        COMPOSE_DOCKER_CLI_BUILD = '0'&#10;    }&#10;&#10;    stages {&#10;&#10;        stage('Clean Workspace') {&#10;            steps {&#10;                echo ' Nettoyage de l\'espace de travail...'&#10;                sh '''&#10;                    # Nettoyer seulement les conteneurs et images de l'ancien build&#10;                    docker-compose down -v --remove-orphans || true&#10;                    docker images | grep &quot;my_buy01_pipeline2&quot; | grep -v &quot;${IMAGE_VERSION}&quot; | awk '{print $3}' | xargs -r docker rmi -f || true&#10;                '''&#10;            }&#10;        }&#10;&#10;        stage('Build &amp; Unit Tests') {&#10;            parallel {&#10;                stage('Frontend') {&#10;                    steps {&#10;                        echo ' Tests Frontend Angular (Headless)...'&#10;                        dir('buy-01-frontend') {&#10;                            sh '''&#10;                                npm ci --cache ${NPM_CONFIG_CACHE}&#10;                                npm run test:headless&#10;                            '''&#10;                        }&#10;                    }&#10;                }&#10;&#10;                stage('Backend Services') {&#10;                    steps {&#10;                        echo ' Build et Tests des Services Backend...'&#10;                        script {&#10;                            def services = ['discovery-service', 'config-service', 'api-gateway', 'product-service', 'user-service', 'media-service']&#10;                            services.each { svc -&gt;&#10;                                echo &quot; Build et test de ${svc}...&quot;&#10;                                sh &quot;&quot;&quot;&#10;                                    mvn -f ${svc}/pom.xml clean verify \&#10;                                        --batch-mode \&#10;                                        -Dmaven.test.failure.ignore=false&#10;                                &quot;&quot;&quot;&#10;                            }&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;            post {&#10;                always {&#10;                    // Les rapports JUnit et les artefacts proviennent des agents; nous archiveons depuis le contrôleur&#10;                    // pour éviter les problèmes d'accès, on copie d'abord les artefacts si nécessaire.&#10;                    junit allowEmptyResults: true, testResults: '**/target/surefire-reports/*.xml'&#10;                    archiveArtifacts artifacts: '**/target/*.jar', allowEmptyArchive: true&#10;                }&#10;            }&#10;        }&#10;&#10;       // groovy&#10;       stage('Code Quality (Sonar + Gate)') {&#10;           steps {&#10;               echo ' Analyses Sonar en parallèle + attente des Quality Gates...'&#10;               script {&#10;                   def services = ['discovery-service','config-service','api-gateway','product-service','user-service','media-service']&#10;                   def parallelQuality = [:]&#10;&#10;                   services.each { svc -&gt;&#10;                       parallelQuality[svc] = {&#10;                           echo &quot; Sonar pour ${svc}...&quot;&#10;                           dir(svc) {&#10;                               // Move the Sonar wrapper and credentials inside each parallel branch&#10;                               withSonarQubeEnv('safe-zone-mr-jenk') {&#10;                                   withCredentials([string(credentialsId: 'SONAR_USER_TOKEN', variable: 'SONAR_USER_TOKEN')]) {&#10;                                       def jacocoOption = (svc in ['product-service','user-service','media-service']) ?&#10;                                           &quot;-Dsonar.coverage.jacoco.xmlReportPaths=target/site/jacoco/jacoco.xml&quot; : &quot;&quot;&#10;&#10;                                       sh &quot;&quot;&quot;&#10;                                           mvn sonar:sonar \&#10;                                               -Dsonar.projectKey=sonar-${svc.replace('-service','')} \&#10;                                               -Dsonar.host.url=$SONAR_HOST_URL \&#10;                                               -Dsonar.token=$SONAR_USER_TOKEN \&#10;                                               -Dsonar.java.binaries=target/classes \&#10;                                               ${jacocoOption}&#10;                                       &quot;&quot;&quot;&#10;                                   } // withCredentials&#10;                               } // withSonarQubeEnv&#10;&#10;                               // waitForQualityGate must run in the same workspace/context&#10;                               timeout(time: 10, unit: 'MINUTES') {&#10;                                   waitForQualityGate abortPipeline: true&#10;                               }&#10;                           } // dir&#10;                       }&#10;                   }&#10;&#10;                   parallel parallelQuality&#10;               }&#10;           }&#10;       }&#10;&#10;&#10;&#10;        stage('Build Docker Images') {&#10;            steps {&#10;                echo ' Construction des images Docker en parallèle...'&#10;                script {&#10;                    def services = ['eureka-server', 'config-service', 'api-gateway', 'product-service', 'user-service', 'media-service', 'frontend']&#10;                    def parallelBuilds = [:]&#10;&#10;                    services.each { service -&gt;&#10;                        parallelBuilds[service] = {&#10;                            def serviceDir = service == 'frontend' ? 'buy-01-frontend' : service.replace('eureka-server', 'discovery-service')&#10;                            echo &quot; Construction de ${service}...&quot;&#10;                            sh &quot;&quot;&quot;&#10;                                docker build -t my_buy01_pipeline2-${service}:latest \&#10;                                    --build-arg MAVEN_OPTS=&quot;-Dmaven.test.skip=true&quot; \&#10;                                    --cache-from ${DOCKER_HUB_USER}/${PROJECT_NAME}-${service}:latest \&#10;                                    -f ${serviceDir}/Dockerfile \&#10;                                    ${serviceDir}&#10;                            &quot;&quot;&quot;&#10;                        }&#10;                    }&#10;&#10;                    parallel parallelBuilds&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Integration Tests') {&#10;            steps {&#10;                echo ' Tests d\'intégration...'&#10;                script {&#10;                    timeout(time: 10, unit: 'MINUTES') {&#10;                        try {&#10;                            withEnv([&#10;                                &quot;IMAGE_VERSION=${env.BUILD_NUMBER}&quot;,&#10;                                &quot;PROJECT_NAME=${PROJECT_NAME}&quot;,&#10;                                &quot;GITHUB_TOKEN=${env.GITHUB_TOKEN}&quot;,&#10;                                &quot;SUPABASE_PROJECT_URL=${env.SUPABASE_PROJECT_URL}&quot;,&#10;                                &quot;SUPABASE_API_KEY=${env.SUPABASE_API_KEY}&quot;,&#10;                                &quot;SUPABASE_BUCKET_NAME=${env.SUPABASE_BUCKET_NAME}&quot;,&#10;                                &quot;MONGODB_URI=${env.MONGODB_URI}&quot;,&#10;                                &quot;MONGODB_DATABASE=${env.MONGODB_DATABASE}&quot;&#10;                            ]) {&#10;                                sh '''&#10;                                    docker-compose up -d&#10;&#10;                                    # Attendre que les services soient prêts avec health checks&#10;                                    echo &quot;⏳ Attente du démarrage des services...&quot;&#10;                                    for i in {1..40}; do&#10;                                        if docker-compose ps | grep -E &quot;(healthy|running)&quot; | wc -l | grep -q 7; then&#10;                                            echo &quot;✅ Tous les services sont démarrés&quot;&#10;                                            break&#10;                                        fi&#10;                                        echo &quot;Tentative $i/40...&quot;&#10;                                        sleep 5&#10;                                    done&#10;&#10;                                    # Vérifier que les services sont en bonne santé&#10;                                    docker-compose ps&#10;                                '''&#10;                            }&#10;                        } finally {&#10;                            sh 'docker-compose logs --tail=50'&#10;                            sh 'docker-compose down -v --remove-orphans'&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Push to Docker Hub') {&#10;            steps {&#10;                script {&#10;                    echo ' Push des images vers Docker Hub...'&#10;&#10;                    withCredentials([usernamePassword(&#10;                        credentialsId: 'dockerhub-credential',&#10;                        usernameVariable: 'DOCKER_USER',&#10;                        passwordVariable: 'DOCKER_PASS'&#10;                    )]) {&#10;                        sh 'echo $DOCKER_PASS | docker login -u $DOCKER_USER --password-stdin'&#10;                    }&#10;&#10;                    def services = ['frontend', 'product-service', 'user-service', 'media-service', 'api-gateway', 'config-service', 'eureka-server']&#10;                    def parallelPushes = [:]&#10;&#10;                    services.each { service -&gt;&#10;                        parallelPushes[service] = {&#10;                            def localImageName = &quot;my_buy01_pipeline2-${service}&quot;&#10;                            // Préfixer avec PROJECT_NAME pour éviter les conflits entre applications&#10;                            def taggedImageName = &quot;${DOCKER_HUB_USER}/${PROJECT_NAME}-${service}:${env.BUILD_NUMBER}&quot;&#10;                            def latestImageName = &quot;${DOCKER_HUB_USER}/${PROJECT_NAME}-${service}:latest&quot;&#10;&#10;                            echo &quot; Push de ${service}...&quot;&#10;                            sh &quot;&quot;&quot;&#10;                                docker tag ${localImageName}:latest ${taggedImageName}&#10;                                docker tag ${localImageName}:latest ${latestImageName}&#10;                                docker push ${taggedImageName}&#10;                                docker push ${latestImageName}&#10;                            &quot;&quot;&quot;&#10;                        }&#10;                    }&#10;&#10;                    parallel parallelPushes&#10;&#10;                    sh 'docker logout'&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Deploy Locally') {&#10;            steps {&#10;                script {&#10;                    echo &quot; Déploiement local, version ${env.BUILD_NUMBER}...&quot;&#10;&#10;                    timeout(time: 10, unit: 'MINUTES') {&#10;                        withEnv([&#10;                            &quot;IMAGE_VERSION=${env.BUILD_NUMBER}&quot;,&#10;                            &quot;PROJECT_NAME=${PROJECT_NAME}&quot;,&#10;                            &quot;GITHUB_TOKEN=${env.GITHUB_TOKEN}&quot;,&#10;                            &quot;SUPABASE_PROJECT_URL=${env.SUPABASE_PROJECT_URL}&quot;,&#10;                            &quot;SUPABASE_API_KEY=${env.SUPABASE_API_KEY}&quot;,&#10;                            &quot;SUPABASE_BUCKET_NAME=${env.SUPABASE_BUCKET_NAME}&quot;,&#10;                            &quot;MONGODB_URI=${env.MONGODB_URI}&quot;,&#10;                            &quot;MONGODB_DATABASE=${env.MONGODB_DATABASE}&quot;&#10;                        ]) {&#10;                            sh '''&#10;                                docker-compose -f docker-compose-deploy.yml down&#10;                                docker-compose -f docker-compose-deploy.yml pull&#10;                                docker-compose -f docker-compose-deploy.yml up -d&#10;&#10;                                # Vérifier l'état des conteneurs&#10;                                echo &quot;⏳ Attente du démarrage...&quot;&#10;                                for i in {1..20}; do&#10;                                    if docker-compose -f docker-compose-deploy.yml ps | grep -q &quot;Up&quot;; then&#10;                                        echo &quot;✅ Services démarrés&quot;&#10;                                        break&#10;                                    fi&#10;                                    echo &quot;Tentative $i/20...&quot;&#10;                                    sleep 3&#10;                                done&#10;                                docker-compose -f docker-compose-deploy.yml ps&#10;                            '''&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Health Check') {&#10;            steps {&#10;                script {&#10;                    echo ' Vérification de la santé des services...'&#10;                    timeout(time: 5, unit: 'MINUTES') {&#10;                        sh '''&#10;                            # Attendre que tous les services soient en bonne santé&#10;                            for i in {1..30}; do&#10;                                if docker-compose -f docker-compose-deploy.yml ps | grep -q &quot;unhealthy&quot;; then&#10;                                    echo &quot;⏳ Attente de la santé des services... ($i/30)&quot;&#10;                                    sleep 10&#10;                                else&#10;                                    echo &quot;✅ Tous les services sont en bonne santé&quot;&#10;                                    exit 0&#10;                                fi&#10;                            done&#10;&#10;                            echo &quot;❌ Timeout: certains services ne sont pas en bonne santé&quot;&#10;                            docker-compose -f docker-compose-deploy.yml ps&#10;                            exit 1&#10;                        '''&#10;                    }&#10;                }&#10;            }&#10;        }&#10;    }&#10;&#10;    post {&#10;        success {&#10;            script {&#10;                // s'assurer que les commandes Docker du post s'exécutent sur le noeud contrôleur&#10;                node {&#10;                    // Nettoyer les anciennes images&#10;                    sh '''&#10;                        docker images | grep &quot;${DOCKER_HUB_USER}&quot; | grep -v &quot;${IMAGE_VERSION}&quot; | grep -v &quot;latest&quot; | awk '{print $3}' | xargs -r docker rmi -f || true&#10;                    '''&#10;&#10;                    mail(&#10;                        to: 'bahmamadoubobosewa@gmail.com',&#10;                        subject: &quot;SUCCESS: Pipeline ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;,&#10;                        body: &quot;Le pipeline a réussi.\nJob: ${env.JOB_NAME}\nBuild: ${env.BUILD_NUMBER}\nVoir les détails: ${env.BUILD_URL}&quot;&#10;                    )&#10;                }&#10;            }&#10;        }&#10;&#10;        failure {&#10;            script {&#10;                echo &quot;⚠️ Pipeline échouée, rollback en cours...&quot;&#10;&#10;                def lastSuccessfulBuild = currentBuild.previousSuccessfulBuild&#10;&#10;                node {&#10;                    if (lastSuccessfulBuild &amp;&amp; lastSuccessfulBuild.number != env.BUILD_NUMBER) {&#10;                        echo &quot; Rollback vers la version ${lastSuccessfulBuild.number}...&quot;&#10;                        try {&#10;                            withEnv([&quot;IMAGE_VERSION=${lastSuccessfulBuild.number}&quot;]) {&#10;                                sh '''&#10;                                    docker-compose -f docker-compose-deploy.yml down&#10;                                    docker-compose -f docker-compose-deploy.yml pull&#10;                                    docker-compose -f docker-compose-deploy.yml up -d&#10;                                '''&#10;                            }&#10;                            echo &quot;✅ Rollback réussi vers la version ${lastSuccessfulBuild.number}&quot;&#10;                        } catch (Exception e) {&#10;                            echo &quot;❌ Échec du rollback: ${e.message}&quot;&#10;                        }&#10;                    } else {&#10;                        echo &quot;⚠️ Aucune version précédente disponible pour rollback.&quot;&#10;                    }&#10;&#10;                    mail(&#10;                        to: 'bahmamadoubosewa@gmail.com',&#10;                        subject: &quot;FAILURE: Pipeline ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;,&#10;                        body: &quot;Le pipeline a echoue.\nJob: ${env.JOB_NAME}\nBuild: ${env.BUILD_NUMBER}\nVoir les détails: ${env.BUILD_URL}&quot;&#10;                    )&#10;                }&#10;            }&#10;        }&#10;&#10;        always {&#10;            script {&#10;                node {&#10;                    echo ' Nettoyage final...'&#10;                    sh '''&#10;                        # Nettoyer les conteneurs arrêtés et les images dangereuses&#10;                        docker container prune -f || true&#10;                        docker image prune -f || true&#10;                    '''&#10;                }&#10;            }&#10;        }&#10;    }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>
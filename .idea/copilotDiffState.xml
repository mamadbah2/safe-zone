<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/Jenkinsfile">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Jenkinsfile" />
              <option name="originalContent" value="// filepath: /home/mamadbah/Java/mr-jenk/Jenkinsfile.optimized&#10;pipeline {&#10;    agent none&#10;&#10;    // NOTE: Tous les stages s'exécutent avec agent any (Jenkins choisit un agent disponible)&#10;&#10;    options {&#10;        buildDiscarder(logRotator(numToKeepStr: '10'))&#10;        timeout(time: 60, unit: 'MINUTES')&#10;        timestamps()&#10;        disableConcurrentBuilds()&#10;    }&#10;&#10;    environment {&#10;        DOCKER_HUB_USER = 'mamadbah2'&#10;        IMAGE_VERSION = &quot;${env.BUILD_NUMBER}&quot;&#10;        GITHUB_TOKEN = credentials('GITHUB_TOKEN')&#10;&#10;        // Media Service credentials&#10;        MONGODB_URI = credentials('MONGODB_URI_BOBO')&#10;        MONGODB_DATABASE = credentials('MONGODB_DATABASE')&#10;        SUPABASE_PROJECT_URL = credentials('SUPABASE_PROJECT_URL')&#10;        SUPABASE_API_KEY = credentials('SUPABASE_API_KEY')&#10;        SUPABASE_BUCKET_NAME = credentials('SUPABASE_BUCKET_NAME')&#10;&#10;        // Cache directories&#10;        MAVEN_OPTS = '-Dmaven.repo.local=.m2/repository'&#10;        NPM_CONFIG_CACHE = '.npm-cache'&#10;    }&#10;&#10;    stages {&#10;&#10;        stage('Clean Workspace') {&#10;            agent any&#10;            steps {&#10;                echo ' Nettoyage de l\'espace de travail...'&#10;                sh '''&#10;                    # Nettoyer seulement les conteneurs et images de l'ancien build&#10;                    docker-compose down -v --remove-orphans || true&#10;                    docker images | grep &quot;my_buy01_pipeline2&quot; | grep -v &quot;${IMAGE_VERSION}&quot; | awk '{print $3}' | xargs -r docker rmi -f || true&#10;                '''&#10;            }&#10;        }&#10;&#10;        stage('Build &amp; Unit Tests') {&#10;            parallel {&#10;                stage('Frontend') {&#10;                    agent any&#10;                    steps {&#10;                        echo ' Tests Frontend Angular (Headless)...'&#10;                        dir('buy-01-frontend') {&#10;                            sh '''&#10;                                npm ci --cache ${NPM_CONFIG_CACHE}&#10;                                npm run test:headless&#10;                            '''&#10;                        }&#10;                    }&#10;                }&#10;&#10;                stage('Backend Services') {&#10;                    agent any&#10;                    steps {&#10;                        echo ' Build et Tests des Services Backend...'&#10;                        sh '''&#10;                            # Build tous les services Maven (utilise le cache MAVEN_OPTS configuré)&#10;                            mvn -T 1C clean test \&#10;                                -f discovery-service/pom.xml \&#10;                                -f config-service/pom.xml \&#10;                                -f api-gateway/pom.xml \&#10;                                -f product-service/pom.xml \&#10;                                -f user-service/pom.xml \&#10;                                -f media-service/pom.xml \&#10;                                --batch-mode \&#10;                                -Dmaven.test.failure.ignore=false&#10;                        '''&#10;                    }&#10;                }&#10;            }&#10;            post {&#10;                always {&#10;                    // Les rapports JUnit et les artefacts proviennent des agents; nous archiveons depuis le contrôleur&#10;                    // pour éviter les problèmes d'accès, on copie d'abord les artefacts si nécessaire.&#10;                    junit allowEmptyResults: true, testResults: '**/target/surefire-reports/*.xml'&#10;                    archiveArtifacts artifacts: '**/target/*.jar', allowEmptyArchive: true&#10;                }&#10;            }&#10;        }&#10;&#10;        // Ajout : SonarQube analysis inspiré de Jenkinsfile(safe)&#10;        stage('Sonar Analysis') {&#10;            agent any&#10;            steps {&#10;                echo ' Exécution des analyses Sonar pour les services backend...'&#10;                script {&#10;                    // Utilise l'environnement Sonar configuré dans Jenkins (withSonarQubeEnv)&#10;                    withSonarQubeEnv('safe-zone-mr-jenk') {&#10;                        withCredentials([string(credentialsId: 'SONAR_USER_TOKEN', variable: 'SONAR_USER_TOKEN')]) {&#10;                            def services = ['discovery-service','config-service','api-gateway','product-service','user-service','media-service']&#10;                            services.each { svc -&gt;&#10;                                echo &quot; Sonar pour ${svc}...&quot;&#10;                                def pom = &quot;${svc}/pom.xml&quot;&#10;                                // Certaines applications produisent des rapports JaCoCo&#10;                                def jacocoOption = ''&#10;                                if (svc in ['product-service','user-service','media-service']) {&#10;                                    jacocoOption = &quot;-Dsonar.coverage.jacoco.xmlReportPaths=${svc}/target/site/jacoco/jacoco.xml&quot;&#10;                                }&#10;&#10;                                sh &quot;&quot;&quot;&#10;                                    mvn -f ${pom} sonar:sonar \&#10;                                        -Dsonar.projectKey=sonar-${svc.replace('-service','')} \&#10;                                        -Dsonar.host.url=$SONAR_HOST_URL \&#10;                                        -Dsonar.login=$SONAR_USER_TOKEN \&#10;                                        ${jacocoOption}&#10;                                &quot;&quot;&quot;&#10;                            }&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Sonar Quality Gate') {&#10;            agent any&#10;            steps {&#10;                timeout(time:25, unit: 'MINUTES') {&#10;                    waitForQualityGate abortPipeline: true&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Build Docker Images') {&#10;            agent any&#10;            steps {&#10;                echo ' Construction des images Docker en parallèle...'&#10;                script {&#10;                    def services = ['eureka-server', 'config-service', 'api-gateway', 'product-service', 'user-service', 'media-service', 'frontend']&#10;                    def parallelBuilds = [:]&#10;&#10;                    services.each { service -&gt;&#10;                        parallelBuilds[service] = {&#10;                            def serviceDir = service == 'frontend' ? 'buy-01-frontend' : service.replace('eureka-server', 'discovery-service')&#10;                            echo &quot; Construction de ${service}...&quot;&#10;                            sh &quot;&quot;&quot;&#10;                                docker build -t my_buy01_pipeline2-${service}:latest \&#10;                                    --build-arg BUILDKIT_INLINE_CACHE=1 \&#10;                                    -f ${serviceDir}/Dockerfile \&#10;                                    ${serviceDir}&#10;                            &quot;&quot;&quot;&#10;                        }&#10;                    }&#10;&#10;                    parallel parallelBuilds&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Integration Tests') {&#10;            agent any&#10;            steps {&#10;                echo ' Tests d\'intégration...'&#10;                script {&#10;                    timeout(time: 10, unit: 'MINUTES') {&#10;                        try {&#10;                            withEnv([&#10;                                &quot;IMAGE_VERSION=${env.BUILD_NUMBER}&quot;,&#10;                                &quot;GITHUB_TOKEN=${env.GITHUB_TOKEN}&quot;,&#10;                                &quot;SUPABASE_PROJECT_URL=${env.SUPABASE_PROJECT_URL}&quot;,&#10;                                &quot;SUPABASE_API_KEY=${env.SUPABASE_API_KEY}&quot;,&#10;                                &quot;SUPABASE_BUCKET_NAME=${env.SUPABASE_BUCKET_NAME}&quot;,&#10;                                &quot;MONGODB_URI=${env.MONGODB_URI}&quot;,&#10;                                &quot;MONGODB_DATABASE=${env.MONGODB_DATABASE}&quot;&#10;                            ]) {&#10;                                sh '''&#10;                                    docker-compose up -d&#10;&#10;                                    # Attendre que les services soient prêts&#10;                                    echo &quot;⏳ Attente du démarrage des services...&quot;&#10;                                    sleep 60&#10;&#10;                                    # Vérifier que les services sont en bonne santé&#10;                                    docker-compose ps&#10;                                '''&#10;                            }&#10;                        } finally {&#10;                            sh 'docker-compose logs --tail=50'&#10;                            sh 'docker-compose down -v --remove-orphans'&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Push to Docker Hub') {&#10;            agent any&#10;            steps {&#10;                script {&#10;                    echo ' Push des images vers Docker Hub...'&#10;&#10;                    withCredentials([usernamePassword(&#10;                        credentialsId: 'dockerhub-credential',&#10;                        usernameVariable: 'DOCKER_USER',&#10;                        passwordVariable: 'DOCKER_PASS'&#10;                    )]) {&#10;                        sh 'echo $DOCKER_PASS | docker login -u $DOCKER_USER --password-stdin'&#10;                    }&#10;&#10;                    def services = ['frontend', 'product-service', 'user-service', 'media-service', 'api-gateway', 'config-service', 'eureka-server']&#10;                    def parallelPushes = [:]&#10;&#10;                    services.each { service -&gt;&#10;                        parallelPushes[service] = {&#10;                            def localImageName = &quot;my_buy01_pipeline2-${service}&quot;&#10;                            def taggedImageName = &quot;${DOCKER_HUB_USER}/${service}:${env.BUILD_NUMBER}&quot;&#10;                            def latestImageName = &quot;${DOCKER_HUB_USER}/${service}:latest&quot;&#10;&#10;                            echo &quot; Push de ${service}...&quot;&#10;                            sh &quot;&quot;&quot;&#10;                                docker tag ${localImageName}:latest ${taggedImageName}&#10;                                docker tag ${localImageName}:latest ${latestImageName}&#10;                                docker push ${taggedImageName}&#10;                                docker push ${latestImageName}&#10;                            &quot;&quot;&quot;&#10;                        }&#10;                    }&#10;&#10;                    parallel parallelPushes&#10;&#10;                    sh 'docker logout'&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Deploy Locally') {&#10;            agent any&#10;            steps {&#10;                script {&#10;                    echo &quot; Déploiement local, version ${env.BUILD_NUMBER}...&quot;&#10;&#10;                    timeout(time: 10, unit: 'MINUTES') {&#10;                        withEnv([&#10;                            &quot;IMAGE_VERSION=${env.BUILD_NUMBER}&quot;,&#10;                            &quot;GITHUB_TOKEN=${env.GITHUB_TOKEN}&quot;,&#10;                            &quot;SUPABASE_PROJECT_URL=${env.SUPABASE_PROJECT_URL}&quot;,&#10;                            &quot;SUPABASE_API_KEY=${env.SUPABASE_API_KEY}&quot;,&#10;                            &quot;SUPABASE_BUCKET_NAME=${env.SUPABASE_BUCKET_NAME}&quot;,&#10;                            &quot;MONGODB_URI=${env.MONGODB_URI}&quot;,&#10;                            &quot;MONGODB_DATABASE=${env.MONGODB_DATABASE}&quot;&#10;                        ]) {&#10;                            sh '''&#10;                                docker-compose -f docker-compose-deploy.yml down&#10;                                docker-compose -f docker-compose-deploy.yml pull&#10;                                docker-compose -f docker-compose-deploy.yml up -d&#10;&#10;                                # Vérifier l'état des conteneurs&#10;                                sleep 30&#10;                                docker-compose -f docker-compose-deploy.yml ps&#10;                            '''&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Health Check') {&#10;            agent any&#10;            steps {&#10;                script {&#10;                    echo ' Vérification de la santé des services...'&#10;                    timeout(time: 5, unit: 'MINUTES') {&#10;                        sh '''&#10;                            # Attendre que tous les services soient en bonne santé&#10;                            for i in {1..30}; do&#10;                                if docker-compose -f docker-compose-deploy.yml ps | grep -q &quot;unhealthy&quot;; then&#10;                                    echo &quot;⏳ Attente de la santé des services... ($i/30)&quot;&#10;                                    sleep 10&#10;                                else&#10;                                    echo &quot;✅ Tous les services sont en bonne santé&quot;&#10;                                    exit 0&#10;                                fi&#10;                            done&#10;&#10;                            echo &quot;❌ Timeout: certains services ne sont pas en bonne santé&quot;&#10;                            docker-compose -f docker-compose-deploy.yml ps&#10;                            exit 1&#10;                        '''&#10;                    }&#10;                }&#10;            }&#10;        }&#10;    }&#10;&#10;    post {&#10;        success {&#10;            script {&#10;                // s'assurer que les commandes Docker du post s'exécutent sur le noeud contrôleur&#10;                node {&#10;                    // Nettoyer les anciennes images&#10;                    sh '''&#10;                        docker images | grep &quot;${DOCKER_HUB_USER}&quot; | grep -v &quot;${IMAGE_VERSION}&quot; | grep -v &quot;latest&quot; | awk '{print $3}' | xargs -r docker rmi -f || true&#10;                    '''&#10;&#10;                    mail(&#10;                        to: 'bahmamadoubobosewa@gmail.com',&#10;                        subject: &quot;SUCCESS: Pipeline ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;,&#10;                        body: &quot;Le pipeline a réussi.\nJob: ${env.JOB_NAME}\nBuild: ${env.BUILD_NUMBER}\nVoir les détails: ${env.BUILD_URL}&quot;&#10;                    )&#10;                }&#10;            }&#10;        }&#10;&#10;        failure {&#10;            script {&#10;                echo &quot;⚠️ Pipeline échouée, rollback en cours...&quot;&#10;&#10;                def lastSuccessfulBuild = currentBuild.previousSuccessfulBuild&#10;&#10;                node {&#10;                    if (lastSuccessfulBuild &amp;&amp; lastSuccessfulBuild.number != env.BUILD_NUMBER) {&#10;                        echo &quot; Rollback vers la version ${lastSuccessfulBuild.number}...&quot;&#10;                        try {&#10;                            withEnv([&quot;IMAGE_VERSION=${lastSuccessfulBuild.number}&quot;]) {&#10;                                sh '''&#10;                                    docker-compose -f docker-compose-deploy.yml down&#10;                                    docker-compose -f docker-compose-deploy.yml pull&#10;                                    docker-compose -f docker-compose-deploy.yml up -d&#10;                                '''&#10;                            }&#10;                            echo &quot;✅ Rollback réussi vers la version ${lastSuccessfulBuild.number}&quot;&#10;                        } catch (Exception e) {&#10;                            echo &quot;❌ Échec du rollback: ${e.message}&quot;&#10;                        }&#10;                    } else {&#10;                        echo &quot;⚠️ Aucune version précédente disponible pour rollback.&quot;&#10;                    }&#10;&#10;                    mail(&#10;                        to: 'bahmamadoubosewa@gmail.com',&#10;                        subject: &quot;FAILURE: Pipeline ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;,&#10;                        body: &quot;Le pipeline a echoue.\nJob: ${env.JOB_NAME}\nBuild: ${env.BUILD_NUMBER}\nVoir les détails: ${env.BUILD_URL}&quot;&#10;                    )&#10;                }&#10;            }&#10;        }&#10;&#10;        always {&#10;            script {&#10;                node {&#10;                    echo ' Nettoyage final...'&#10;                    sh '''&#10;                        # Nettoyer les conteneurs arrêtés et les images dangereuses&#10;                        docker container prune -f || true&#10;                        docker image prune -f || true&#10;                    '''&#10;                }&#10;            }&#10;        }&#10;    }&#10;}&#10;" />
              <option name="updatedContent" value="// filepath: /home/mamadbah/Java/mr-jenk/Jenkinsfile.optimized&#10;pipeline {&#10;    agent any&#10;&#10;    // NOTE: Tous les stages s'exécutent sur le même agent (Jenkins choisit un agent disponible)&#10;&#10;    options {&#10;        buildDiscarder(logRotator(numToKeepStr: '10'))&#10;        timeout(time: 60, unit: 'MINUTES')&#10;        timestamps()&#10;        disableConcurrentBuilds()&#10;    }&#10;&#10;    environment {&#10;        DOCKER_HUB_USER = 'mamadbah2'&#10;        IMAGE_VERSION = &quot;${env.BUILD_NUMBER}&quot;&#10;        GITHUB_TOKEN = credentials('GITHUB_TOKEN')&#10;&#10;        // Media Service credentials&#10;        MONGODB_URI = credentials('MONGODB_URI_BOBO')&#10;        MONGODB_DATABASE = credentials('MONGODB_DATABASE')&#10;        SUPABASE_PROJECT_URL = credentials('SUPABASE_PROJECT_URL')&#10;        SUPABASE_API_KEY = credentials('SUPABASE_API_KEY')&#10;        SUPABASE_BUCKET_NAME = credentials('SUPABASE_BUCKET_NAME')&#10;&#10;        // Cache directories&#10;        MAVEN_OPTS = '-Dmaven.repo.local=.m2/repository'&#10;        NPM_CONFIG_CACHE = '.npm-cache'&#10;    }&#10;&#10;    stages {&#10;&#10;        stage('Clean Workspace') {&#10;            steps {&#10;                echo ' Nettoyage de l\'espace de travail...'&#10;                sh '''&#10;                    # Nettoyer seulement les conteneurs et images de l'ancien build&#10;                    docker-compose down -v --remove-orphans || true&#10;                    docker images | grep &quot;my_buy01_pipeline2&quot; | grep -v &quot;${IMAGE_VERSION}&quot; | awk '{print $3}' | xargs -r docker rmi -f || true&#10;                '''&#10;            }&#10;        }&#10;&#10;        stage('Build &amp; Unit Tests') {&#10;            parallel {&#10;                stage('Frontend') {&#10;                    steps {&#10;                        echo ' Tests Frontend Angular (Headless)...'&#10;                        dir('buy-01-frontend') {&#10;                            sh '''&#10;                                npm ci --cache ${NPM_CONFIG_CACHE}&#10;                                npm run test:headless&#10;                            '''&#10;                        }&#10;                    }&#10;                }&#10;&#10;                stage('Backend Services') {&#10;                    steps {&#10;                        echo ' Build et Tests des Services Backend...'&#10;                        sh '''&#10;                            # Build tous les services Maven (utilise le cache MAVEN_OPTS configuré)&#10;                            mvn -T 1C clean test \&#10;                                -f discovery-service/pom.xml \&#10;                                -f config-service/pom.xml \&#10;                                -f api-gateway/pom.xml \&#10;                                -f product-service/pom.xml \&#10;                                -f user-service/pom.xml \&#10;                                -f media-service/pom.xml \&#10;                                --batch-mode \&#10;                                -Dmaven.test.failure.ignore=false&#10;                        '''&#10;                    }&#10;                }&#10;            }&#10;            post {&#10;                always {&#10;                    // Les rapports JUnit et les artefacts proviennent des agents; nous archiveons depuis le contrôleur&#10;                    // pour éviter les problèmes d'accès, on copie d'abord les artefacts si nécessaire.&#10;                    junit allowEmptyResults: true, testResults: '**/target/surefire-reports/*.xml'&#10;                    archiveArtifacts artifacts: '**/target/*.jar', allowEmptyArchive: true&#10;                }&#10;            }&#10;        }&#10;&#10;        // Ajout : SonarQube analysis inspiré de Jenkinsfile(safe)&#10;        stage('Sonar Analysis') {&#10;            steps {&#10;                echo ' Exécution des analyses Sonar pour les services backend...'&#10;                script {&#10;                    // Utilise l'environnement Sonar configuré dans Jenkins (withSonarQubeEnv)&#10;                    withSonarQubeEnv('safe-zone-mr-jenk') {&#10;                        withCredentials([string(credentialsId: 'SONAR_USER_TOKEN', variable: 'SONAR_USER_TOKEN')]) {&#10;                            def services = ['discovery-service','config-service','api-gateway','product-service','user-service','media-service']&#10;                            services.each { svc -&gt;&#10;                                echo &quot; Sonar pour ${svc}...&quot;&#10;                                def pom = &quot;${svc}/pom.xml&quot;&#10;                                // Certaines applications produisent des rapports JaCoCo&#10;                                def jacocoOption = ''&#10;                                if (svc in ['product-service','user-service','media-service']) {&#10;                                    jacocoOption = &quot;-Dsonar.coverage.jacoco.xmlReportPaths=${svc}/target/site/jacoco/jacoco.xml&quot;&#10;                                }&#10;&#10;                                sh &quot;&quot;&quot;&#10;                                    mvn -f ${pom} sonar:sonar \&#10;                                        -Dsonar.projectKey=sonar-${svc.replace('-service','')} \&#10;                                        -Dsonar.host.url=$SONAR_HOST_URL \&#10;                                        -Dsonar.login=$SONAR_USER_TOKEN \&#10;                                        ${jacocoOption}&#10;                                &quot;&quot;&quot;&#10;                            }&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Sonar Quality Gate') {&#10;            steps {&#10;                timeout(time:25, unit: 'MINUTES') {&#10;                    waitForQualityGate abortPipeline: true&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Build Docker Images') {&#10;            steps {&#10;                echo ' Construction des images Docker en parallèle...'&#10;                script {&#10;                    def services = ['eureka-server', 'config-service', 'api-gateway', 'product-service', 'user-service', 'media-service', 'frontend']&#10;                    def parallelBuilds = [:]&#10;&#10;                    services.each { service -&gt;&#10;                        parallelBuilds[service] = {&#10;                            def serviceDir = service == 'frontend' ? 'buy-01-frontend' : service.replace('eureka-server', 'discovery-service')&#10;                            echo &quot; Construction de ${service}...&quot;&#10;                            sh &quot;&quot;&quot;&#10;                                docker build -t my_buy01_pipeline2-${service}:latest \&#10;                                    --build-arg BUILDKIT_INLINE_CACHE=1 \&#10;                                    -f ${serviceDir}/Dockerfile \&#10;                                    ${serviceDir}&#10;                            &quot;&quot;&quot;&#10;                        }&#10;                    }&#10;&#10;                    parallel parallelBuilds&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Integration Tests') {&#10;            agent any&#10;            steps {&#10;                echo ' Tests d\'intégration...'&#10;                script {&#10;                    timeout(time: 10, unit: 'MINUTES') {&#10;                        try {&#10;                            withEnv([&#10;                                &quot;IMAGE_VERSION=${env.BUILD_NUMBER}&quot;,&#10;                                &quot;GITHUB_TOKEN=${env.GITHUB_TOKEN}&quot;,&#10;                                &quot;SUPABASE_PROJECT_URL=${env.SUPABASE_PROJECT_URL}&quot;,&#10;                                &quot;SUPABASE_API_KEY=${env.SUPABASE_API_KEY}&quot;,&#10;                                &quot;SUPABASE_BUCKET_NAME=${env.SUPABASE_BUCKET_NAME}&quot;,&#10;                                &quot;MONGODB_URI=${env.MONGODB_URI}&quot;,&#10;                                &quot;MONGODB_DATABASE=${env.MONGODB_DATABASE}&quot;&#10;                            ]) {&#10;                                sh '''&#10;                                    docker-compose up -d&#10;&#10;                                    # Attendre que les services soient prêts&#10;                                    echo &quot;⏳ Attente du démarrage des services...&quot;&#10;                                    sleep 60&#10;&#10;                                    # Vérifier que les services sont en bonne santé&#10;                                    docker-compose ps&#10;                                '''&#10;                            }&#10;                        } finally {&#10;                            sh 'docker-compose logs --tail=50'&#10;                            sh 'docker-compose down -v --remove-orphans'&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Push to Docker Hub') {&#10;            agent any&#10;            steps {&#10;                script {&#10;                    echo ' Push des images vers Docker Hub...'&#10;&#10;                    withCredentials([usernamePassword(&#10;                        credentialsId: 'dockerhub-credential',&#10;                        usernameVariable: 'DOCKER_USER',&#10;                        passwordVariable: 'DOCKER_PASS'&#10;                    )]) {&#10;                        sh 'echo $DOCKER_PASS | docker login -u $DOCKER_USER --password-stdin'&#10;                    }&#10;&#10;                    def services = ['frontend', 'product-service', 'user-service', 'media-service', 'api-gateway', 'config-service', 'eureka-server']&#10;                    def parallelPushes = [:]&#10;&#10;                    services.each { service -&gt;&#10;                        parallelPushes[service] = {&#10;                            def localImageName = &quot;my_buy01_pipeline2-${service}&quot;&#10;                            def taggedImageName = &quot;${DOCKER_HUB_USER}/${service}:${env.BUILD_NUMBER}&quot;&#10;                            def latestImageName = &quot;${DOCKER_HUB_USER}/${service}:latest&quot;&#10;&#10;                            echo &quot; Push de ${service}...&quot;&#10;                            sh &quot;&quot;&quot;&#10;                                docker tag ${localImageName}:latest ${taggedImageName}&#10;                                docker tag ${localImageName}:latest ${latestImageName}&#10;                                docker push ${taggedImageName}&#10;                                docker push ${latestImageName}&#10;                            &quot;&quot;&quot;&#10;                        }&#10;                    }&#10;&#10;                    parallel parallelPushes&#10;&#10;                    sh 'docker logout'&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Deploy Locally') {&#10;            agent any&#10;            steps {&#10;                script {&#10;                    echo &quot; Déploiement local, version ${env.BUILD_NUMBER}...&quot;&#10;&#10;                    timeout(time: 10, unit: 'MINUTES') {&#10;                        withEnv([&#10;                            &quot;IMAGE_VERSION=${env.BUILD_NUMBER}&quot;,&#10;                            &quot;GITHUB_TOKEN=${env.GITHUB_TOKEN}&quot;,&#10;                            &quot;SUPABASE_PROJECT_URL=${env.SUPABASE_PROJECT_URL}&quot;,&#10;                            &quot;SUPABASE_API_KEY=${env.SUPABASE_API_KEY}&quot;,&#10;                            &quot;SUPABASE_BUCKET_NAME=${env.SUPABASE_BUCKET_NAME}&quot;,&#10;                            &quot;MONGODB_URI=${env.MONGODB_URI}&quot;,&#10;                            &quot;MONGODB_DATABASE=${env.MONGODB_DATABASE}&quot;&#10;                        ]) {&#10;                            sh '''&#10;                                docker-compose -f docker-compose-deploy.yml down&#10;                                docker-compose -f docker-compose-deploy.yml pull&#10;                                docker-compose -f docker-compose-deploy.yml up -d&#10;&#10;                                # Vérifier l'état des conteneurs&#10;                                sleep 30&#10;                                docker-compose -f docker-compose-deploy.yml ps&#10;                            '''&#10;                        }&#10;                    }&#10;                }&#10;            }&#10;        }&#10;&#10;        stage('Health Check') {&#10;            agent any&#10;            steps {&#10;                script {&#10;                    echo ' Vérification de la santé des services...'&#10;                    timeout(time: 5, unit: 'MINUTES') {&#10;                        sh '''&#10;                            # Attendre que tous les services soient en bonne santé&#10;                            for i in {1..30}; do&#10;                                if docker-compose -f docker-compose-deploy.yml ps | grep -q &quot;unhealthy&quot;; then&#10;                                    echo &quot;⏳ Attente de la santé des services... ($i/30)&quot;&#10;                                    sleep 10&#10;                                else&#10;                                    echo &quot;✅ Tous les services sont en bonne santé&quot;&#10;                                    exit 0&#10;                                fi&#10;                            done&#10;&#10;                            echo &quot;❌ Timeout: certains services ne sont pas en bonne santé&quot;&#10;                            docker-compose -f docker-compose-deploy.yml ps&#10;                            exit 1&#10;                        '''&#10;                    }&#10;                }&#10;            }&#10;        }&#10;    }&#10;&#10;    post {&#10;        success {&#10;            script {&#10;                // s'assurer que les commandes Docker du post s'exécutent sur le noeud contrôleur&#10;                node {&#10;                    // Nettoyer les anciennes images&#10;                    sh '''&#10;                        docker images | grep &quot;${DOCKER_HUB_USER}&quot; | grep -v &quot;${IMAGE_VERSION}&quot; | grep -v &quot;latest&quot; | awk '{print $3}' | xargs -r docker rmi -f || true&#10;                    '''&#10;&#10;                    mail(&#10;                        to: 'bahmamadoubobosewa@gmail.com',&#10;                        subject: &quot;SUCCESS: Pipeline ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;,&#10;                        body: &quot;Le pipeline a réussi.\nJob: ${env.JOB_NAME}\nBuild: ${env.BUILD_NUMBER}\nVoir les détails: ${env.BUILD_URL}&quot;&#10;                    )&#10;                }&#10;            }&#10;        }&#10;&#10;        failure {&#10;            script {&#10;                echo &quot;⚠️ Pipeline échouée, rollback en cours...&quot;&#10;&#10;                def lastSuccessfulBuild = currentBuild.previousSuccessfulBuild&#10;&#10;                node {&#10;                    if (lastSuccessfulBuild &amp;&amp; lastSuccessfulBuild.number != env.BUILD_NUMBER) {&#10;                        echo &quot; Rollback vers la version ${lastSuccessfulBuild.number}...&quot;&#10;                        try {&#10;                            withEnv([&quot;IMAGE_VERSION=${lastSuccessfulBuild.number}&quot;]) {&#10;                                sh '''&#10;                                    docker-compose -f docker-compose-deploy.yml down&#10;                                    docker-compose -f docker-compose-deploy.yml pull&#10;                                    docker-compose -f docker-compose-deploy.yml up -d&#10;                                '''&#10;                            }&#10;                            echo &quot;✅ Rollback réussi vers la version ${lastSuccessfulBuild.number}&quot;&#10;                        } catch (Exception e) {&#10;                            echo &quot;❌ Échec du rollback: ${e.message}&quot;&#10;                        }&#10;                    } else {&#10;                        echo &quot;⚠️ Aucune version précédente disponible pour rollback.&quot;&#10;                    }&#10;&#10;                    mail(&#10;                        to: 'bahmamadoubosewa@gmail.com',&#10;                        subject: &quot;FAILURE: Pipeline ${env.JOB_NAME} [${env.BUILD_NUMBER}]&quot;,&#10;                        body: &quot;Le pipeline a echoue.\nJob: ${env.JOB_NAME}\nBuild: ${env.BUILD_NUMBER}\nVoir les détails: ${env.BUILD_URL}&quot;&#10;                    )&#10;                }&#10;            }&#10;        }&#10;&#10;        always {&#10;            script {&#10;                node {&#10;                    echo ' Nettoyage final...'&#10;                    sh '''&#10;                        # Nettoyer les conteneurs arrêtés et les images dangereuses&#10;                        docker container prune -f || true&#10;                        docker image prune -f || true&#10;                    '''&#10;                }&#10;            }&#10;        }&#10;    }&#10;}&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>